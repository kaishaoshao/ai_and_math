# Triton中文站教程

* [ ] 向量相加
* [ ] 融合Softmax(Fused Softmax)
* [ ] 矩阵乘法
* [ ] 低内存
* [ ] 层标准化
* [ ] 融合注意力
* [ ] Libdevice(tl_extra.libdevice)函数
* [ ] 分组GEMM
* [ ] 持久矩阵乘法(Persistent Matmul)

## 向量相加

### 1.导入装饰器

* `triton`是Triton框架的主模块，用于GPU编程
* `triton.language`提供Triton的内置函数和语法(如内存操作、并行指令)
* `@triton.jit`是装饰器，表示下方函数是一个Triton内核，将被编译为GPU可执行代码

### 2.内核函数参数

````python
def add_kernel(
    x_ptr,        # 指向第一个输入向量的指针
    y_ptr,        # 指向第二个输入向量的指针
    output_ptr,   # 指向输出向量的指针
    N_elements,   # 向量长度
    BLOCK_SIZE: tl.constexpr,  # 每个线程块处理的元素数（编译时常量）
):
````

* `tl.constexpr` 编译时常量 —— 修饰的变量在内核函数的编译阶段必须是一个已知的常量值。这意味着它的值不能在运行时动态改变，而是在代码编写时就已经确定。确保变量在编译时已知，便于编译器优化（循环展开，内存访问优化）。

### 3. 线程索引块计算

* `tl.program_id（axis=0）` :获取当前线程块在 1D 启动网格中的索引。沿着第一个轴（通常是行或一维网格中的唯一轴）获取索引，例如，总共有 4 个线程块时，索引为 0、1、2、3。
* `block_start`：当前线程块处理的第一个元素在全局内存中的偏移量。例如，若 `BLOCK_SIZE=64`，第 0 个块处理元素 `0-63`，第 1 个块处理 `64-127`，依此类推。

### 4.元素偏移与掩码

**`offset = block_start + tl.arange(0, BLOCK_SIZE)`**

- 将 `block_start` 和 `tl.arange(0, BLOCK_SIZE)` 相加，得到当前线程块处理的元素的全局偏移量。
- 假设 `BLOCK_SIZE = 4`，`block_start = 8`，那么：

  复制

  ```
  offset = 8 + [0, 1, 2, 3] = [8, 9, 10, 11]
  ```
- 这意味着当前线程块处理的元素在全局数据中的索引是 `[8, 9, 10, 11]`。
- **`mask`**：布尔掩码，标记哪些偏移是有效的（防止处理超出向量长度的元素）。

### 5.加载数据

- **`tl.load`**：从全局内存加载数据到寄存器。
- **`mask=mask`**：仅加载有效偏移的数据，无效位置的值会被忽略

### 6.计算与存储

- **`x + y`**：逐元素相加。
- **`tl.store`**：将结果写回全局内存，同样使用 `mask` 确保只写入有效位置

### 7.内核执行逻辑

- **线程块分配**：总线程块数 = `ceil(N_elements / BLOCK_SIZE)`。
- **掩码作用**：当 `N_elements` 不是 `BLOCK_SIZE` 的整数倍时，最后一个块的部分线程会被禁用。
- **并行性**：每个线程处理一个元素，整个内核通过多个线程块并行执行。
